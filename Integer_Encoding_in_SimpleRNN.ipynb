{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7qLYAniE_SJ"
      },
      "outputs": [],
      "source": [
        "doc = {\n",
        "    'jai ho',\n",
        "    'heetega bhai jeetega india jeetega',\n",
        "    'bharat mata ki jai ho',\n",
        "    'modi ji jindabaad',\n",
        "    'inqulab',\n",
        "    'jindabaad',\n",
        "    'hurryy hurryy',\n",
        "    'can i help you',\n",
        "    'ohh that you',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(oov_token = 'nothing')"
      ],
      "metadata": {
        "id": "37DnOLxKHLTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(doc)"
      ],
      "metadata": {
        "id": "_nq7gmxsHlkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this will print all the unique words\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0grfUEdHzqu",
        "outputId": "e6882821-90ec-4965-c52c-42ab28251457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nothing': 1,\n",
              " 'jai': 2,\n",
              " 'ho': 3,\n",
              " 'you': 4,\n",
              " 'hurryy': 5,\n",
              " 'jindabaad': 6,\n",
              " 'jeetega': 7,\n",
              " 'bharat': 8,\n",
              " 'mata': 9,\n",
              " 'ki': 10,\n",
              " 'ohh': 11,\n",
              " 'that': 12,\n",
              " 'inqulab': 13,\n",
              " 'modi': 14,\n",
              " 'ji': 15,\n",
              " 'heetega': 16,\n",
              " 'bhai': 17,\n",
              " 'india': 18,\n",
              " 'can': 19,\n",
              " 'i': 20,\n",
              " 'help': 21}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now count the word frequency\n",
        "tokenizer.word_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NmZpke1ICon",
        "outputId": "08d58eb1-55bb-4280-c95a-0e4a8d7e8511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('jai', 2),\n",
              "             ('ho', 2),\n",
              "             ('bharat', 1),\n",
              "             ('mata', 1),\n",
              "             ('ki', 1),\n",
              "             ('ohh', 1),\n",
              "             ('that', 1),\n",
              "             ('you', 2),\n",
              "             ('hurryy', 2),\n",
              "             ('jindabaad', 2),\n",
              "             ('inqulab', 1),\n",
              "             ('modi', 1),\n",
              "             ('ji', 1),\n",
              "             ('heetega', 1),\n",
              "             ('bhai', 1),\n",
              "             ('jeetega', 2),\n",
              "             ('india', 1),\n",
              "             ('can', 1),\n",
              "             ('i', 1),\n",
              "             ('help', 1)])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to count the number of sentences in the doc\n",
        "tokenizer.document_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yq_7nlPIXy0",
        "outputId": "4ae6f262-4710-4d38-efd8-1883bf053653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now arranging sentences according to index values\n",
        "sequences = tokenizer.texts_to_sequences(doc)\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLxlW8TAIl3P",
        "outputId": "72b121bf-706a-4e82-dc77-d52a4764a3b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 3],\n",
              " [8, 9, 10, 2, 3],\n",
              " [11, 12, 4],\n",
              " [5, 5],\n",
              " [6],\n",
              " [13],\n",
              " [14, 15, 6],\n",
              " [16, 17, 7, 18, 7],\n",
              " [19, 20, 21, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now adding padding to each sentence to make all of same size\n",
        "from keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "ZBebpl5kJEqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = pad_sequences(sequences,padding='post')\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lynRFiOoJXER",
        "outputId": "1283c35a-8fdb-40e1-ff5b-c39b4c0ac396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2,  3,  0,  0,  0],\n",
              "       [ 8,  9, 10,  2,  3],\n",
              "       [11, 12,  4,  0,  0],\n",
              "       [ 5,  5,  0,  0,  0],\n",
              "       [ 6,  0,  0,  0,  0],\n",
              "       [13,  0,  0,  0,  0],\n",
              "       [14, 15,  6,  0,  0],\n",
              "       [16, 17,  7, 18,  7],\n",
              "       [19, 20, 21,  4,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(oov_token = 'nothing')\n",
        "tokenizer.fit_on_texts(doc)\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "id": "gJrGcvyWJhDz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}